{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_learning_2_Linear_Regression",
      "provenance": [],
      "authorship_tag": "ABX9TyPswa+Y3sUty3aUUQwWsMF8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NScee3KoRlZk",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression\n",
        "Well, why not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW2OYg7bR7Vw",
        "colab_type": "text"
      },
      "source": [
        "Predicting blah blah blah from blah blah using linear regression with pytorch. Back to basics I guess. If I had a cuda core for everytime a tutorial started with this, I would be owning an Nvidia v100 by now. But then again, this exists for a reason. This is for me to come back in a few years to relearn stuff. Hello future me!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SbOfLgJSP8h",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/file/d/1K4Ks_eHx9KthxBOOKpgr5E08sBJXQ8nF/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4uiaaZVZ6mv",
        "colab_type": "text"
      },
      "source": [
        "# By the way, ctrl+shift+space shows docstring in colab\n",
        "unlike the Shift+Tab in jupyterlab/notebook and mouseover in kite vscode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BnwM7cxVRAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZgIBL6-XSoY",
        "colab_type": "text"
      },
      "source": [
        "## Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmwrDWMIXhmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Predicting yeild of apples and oranges\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119]], dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlXm6CU2X8PG",
        "colab_type": "text"
      },
      "source": [
        "Convert inputs and targets to pytorch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqGfsd4eYBRQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "13a3f7fa-41d8-4572-cf27-2b0aaa14f416"
      },
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIZUynRnYSmc",
        "colab_type": "text"
      },
      "source": [
        "yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
        "\n",
        "yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfBn6qY8YyS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9977d3e9-9e3b-42f1-893f-896e8edb1b8c"
      },
      "source": [
        "# Random weights and biases\n",
        "W = torch.randn(2, 3, requires_grad=True) # Transposed later\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "W, b"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.3597, -0.6619, -0.4024],\n",
              "         [ 1.9509,  0.4882,  0.3386]], requires_grad=True),\n",
              " tensor([-0.4954, -0.2067], requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlE2mZ2Daxpx",
        "colab_type": "text"
      },
      "source": [
        "## Defining a model in Pytorch\n",
        "Here, inputs x W^T + b = yeild\n",
        "\n",
        "@ means matMul in pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0ToI4LybnEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(x):\n",
        "    return x @ W.t() + b # here, t() is a method for transpose\n",
        "\n",
        "# Wait, what? That's it? WOW!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNl-nI4Wb9X4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "4d5c2c93-8296-4fec-b31e-f72646bb62fb"
      },
      "source": [
        "# dummy direct predictions\n",
        "preds = model(inputs)\n",
        "print(preds) # Wow, no wonder people say it is easier"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-35.8852, 189.4800],\n",
            "        [-51.7603, 241.9596],\n",
            "        [-81.2323, 254.5793],\n",
            "        [ -7.1528, 232.3100],\n",
            "        [-67.3841, 204.9757]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xEfpM-gcbiR",
        "colab_type": "text"
      },
      "source": [
        "Wow, yeild of oranges is negative: Should we feed oranges to the tree or something? Anyway, let's train it then. Forget AI, it is oranges that is gonna take over the world."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kaytlvtebOD",
        "colab_type": "text"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sElBDMMhelDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse(t1, t2):\n",
        "    diff = t1-t2\n",
        "    return torch.sum(diff*diff) / diff.numel() # numel() returns the number of elements"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2-3K5ZvfXle",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3d7d39cb-e58d-4e4e-f7e3-e92c2ead5ad9"
      },
      "source": [
        "# compute loss\n",
        "loss = mse(preds, targets); loss"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(19050.6230, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoJvntadfdb5",
        "colab_type": "text"
      },
      "source": [
        "## Compute Gradients\n",
        "Compute the gradients of loss with respect to weigts and biases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4_6k9B9gCBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute gradients of loss\n",
        "loss.backward(retain_graph=True)\n",
        "# Now the gradients are stored in the .grad property of respective tensors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCjD_NLigQNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "3e29a0c8-ac5c-4376-dbea-cc237c5995c7"
      },
      "source": [
        "print(W)\n",
        "print(W.grad)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3597, -0.6619, -0.4024],\n",
            "        [ 1.9509,  0.4882,  0.3386]], requires_grad=True)\n",
            "tensor([[-10187.8223, -12456.1592,  -7413.3486],\n",
            "        [ 11596.1416,  10670.6445,   6891.0840]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYCX2DqegUSg",
        "colab_type": "text"
      },
      "source": [
        "NOTE: Pytorch accumulates gradients. So the next time I call .backward(), the new gradient values will get added to the current ones. Hence we need to reset the gradients using .grad.zero_() as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIC_zDPVhqfM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "99b01708-e425-4e5f-d9d8-b74631f9b946"
      },
      "source": [
        "W.grad.zero_()\n",
        "b.grad.zero_()\n",
        "W.grad, b.grad"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.],\n",
              "         [0., 0., 0.]]), tensor([0., 0.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OinalBSeh0-6",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiFZAxkMh4_9",
        "colab_type": "text"
      },
      "source": [
        "Algorithm\n",
        "\n",
        "1. Predict\n",
        "2. Get loss\n",
        "3. Compute gradient of loss w.r.t W and b\n",
        "4. Adjust W and b by subtracting a small quantity proportional to the gradient\n",
        "5. Reset grad to 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4xOS2IpidIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "07d00078-6113-4b42-aae9-cc6529d16002"
      },
      "source": [
        "# Generate prediction\n",
        "loss = mse(preds, targets)\n",
        "print(loss)\n",
        "# Compute Gradients\n",
        "loss.backward() # had to put retain_graph=True on the first backward() call to avoid error\n",
        "print(W.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(19050.6230, grad_fn=<DivBackward0>)\n",
            "tensor([[-10187.8223, -12456.1592,  -7413.3486],\n",
            "        [ 11596.1416,  10670.6445,   6891.0840]])\n",
            "tensor([-124.8829,  132.6609])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra7ZM0LJjkxB",
        "colab_type": "text"
      },
      "source": [
        "We should not track, calculate or modify gradients while updatinng weights. Hence add this in the scope of torch.no_grad(). After updating the weights, reset gradients to zero to prevent gradients from accumulating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K3-reEnk1NJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eta = 1e-5 # learning rate\n",
        "with torch.no_grad():\n",
        "    W -= eta*W.grad\n",
        "    b -= eta*b.grad\n",
        "    W.grad.zero_()\n",
        "    b.grad.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoPpSIpbletb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b31391f7-402a-4585-ffa9-f01b5c358e59"
      },
      "source": [
        "# New loss:\n",
        "preds = model(inputs)\n",
        "print('previous loss = ', loss)\n",
        "loss = mse(preds, targets)\n",
        "print('new loss = ',loss)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "previous loss =  tensor(19050.6230, grad_fn=<DivBackward0>)\n",
            "new loss =  tensor(13496.8125, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_GPgBFolwGj",
        "colab_type": "text"
      },
      "source": [
        "## Training for 100 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP2U8xI8l4J9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea2c7b6f-5b97-4745-bbf4-cdec95681916"
      },
      "source": [
        "eta = 1e-5\n",
        "for i in range(200):\n",
        "    preds = model(inputs)\n",
        "    loss = mse(preds, targets)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        W -= eta*W.grad\n",
        "        b -= eta*b.grad\n",
        "        W.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "\n",
        "preds = model(inputs)\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(76.8011, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4sDZySDmteo",
        "colab_type": "text"
      },
      "source": [
        "Maybe they got a point that this is easier. My TF 1.13 mind is considered officially blown. Thank god for TF2, Thank god for eager execution. Im done with tf.Session()"
      ]
    }
  ]
}